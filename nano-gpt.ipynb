{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3939702e-b4ca-4b64-9184-f8bf0a03aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-29 11:10:33--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-04-29 11:10:35 (17.8 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tiny Shakeaspeare text\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ddb8fa09-0a7b-4e0e-a1ef-392b0101d987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('input.txt','r') as f:\n",
    "    text = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dbee8584-e1ea-4d33-a86c-fe1f22dc94e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
      "vocab_size=64\n"
     ]
    }
   ],
   "source": [
    "# Concat lines\n",
    "text_concat = ''\n",
    "for t in text:\n",
    "    text_concat += t\n",
    "\n",
    "vocab_size = len(chars)\n",
    "chars = sorted(list(set(text_concat)))\n",
    "\n",
    "print(' '.join(chars))\n",
    "print(f'{vocab_size=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "52fd796d-5b8d-4b6d-b6a6-83f795dc7502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 52, 38, 52, 0, 43, 52, 46, 0, 38, 0, 53, 55, 38, 40, 38]\n",
      "Joao foi a praca\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer - character level tokenizer\n",
    "stoi = {c: i for i,c in enumerate(chars)}\n",
    "itos = {i: c for i,c in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[t] for t in s]\n",
    "decode = lambda d: ''.join([itos[i] for i in d])\n",
    "\n",
    "print(encode('Joao foi a praca'))\n",
    "print(decode([21, 52, 38, 52, 0, 43, 52, 46, 0, 38, 0, 53, 55, 38, 40, 38]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f06771b3-c1f8-40b7-98a2-7e8824c66797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115389]) torch.int64\n",
      "tensor([17, 46, 55, 56, 57,  0, 14, 46, 57, 46, 63, 42, 51,  9,  0, 13, 42, 43,\n",
      "        52, 55, 42,  0, 60, 42,  0, 53, 55, 52, 40, 42, 42, 41,  0, 38, 51, 62,\n",
      "         0, 43, 58, 55, 57, 45, 42, 55,  5,  0, 45, 42, 38, 55,  0, 50, 42,  0,\n",
      "        56, 53, 42, 38, 48,  7,  0,  0, 12, 49, 49,  9,  0, 30, 53, 42, 38, 48,\n",
      "         5,  0, 56, 53, 42, 38, 48,  7,  0,  0, 17, 46, 55, 56, 57,  0, 14, 46,\n",
      "        57, 46, 63, 42, 51,  9,  0, 36, 52, 58,  0, 38, 55, 42,  0, 38, 49, 49,\n",
      "         0, 55, 42, 56, 52, 49, 59, 42, 41,  0, 55, 38, 57, 45, 42, 55,  0, 57,\n",
      "        52,  0, 41, 46, 42,  0, 57, 45, 38, 51,  0, 57, 52,  0, 43, 38, 50, 46,\n",
      "        56, 45, 11,  0,  0, 12, 49, 49,  9,  0, 29, 42, 56, 52, 49, 59, 42, 41,\n",
      "         7,  0, 55, 42, 56, 52, 49, 59, 42, 41,  7,  0,  0, 17, 46, 55, 56, 57,\n",
      "         0, 14, 46, 57, 46, 63, 42, 51,  9,  0, 17, 46, 55, 56, 57,  5,  0, 62,\n",
      "        52, 58,  0, 48, 51, 52, 60,  0, 14, 38, 46, 58, 56,  0, 24, 38, 55, 40,\n",
      "        46, 58, 56,  0, 46, 56,  0, 40, 45, 46, 42, 43,  0, 42, 51, 42, 50, 62,\n",
      "         0, 57, 52,  0, 57, 45, 42,  0, 53, 42, 52, 53, 49, 42,  7,  0,  0, 12,\n",
      "        49, 49,  9,  0, 34, 42,  0, 48, 51, 52, 60,  4, 57,  5,  0, 60, 42,  0,\n",
      "        48, 51, 52, 60,  4, 57,  7,  0,  0, 17, 46, 55, 56, 57,  0, 14, 46, 57,\n",
      "        46, 63, 42, 51,  9,  0, 23, 42, 57,  0, 58, 56,  0, 48, 46, 49, 49,  0,\n",
      "        45, 46, 50,  5,  0, 38, 51, 41,  0, 60, 42,  4, 49, 49,  0, 45, 38, 59,\n",
      "        42,  0, 40, 52, 55, 51,  0, 38, 57,  0, 52, 58, 55,  0, 52, 60, 51,  0,\n",
      "        53, 55, 46, 40, 42,  7,  0, 20, 56,  4, 57,  0, 38,  0, 59, 42, 55, 41,\n",
      "        46, 40, 57, 11,  0,  0, 12, 49, 49,  9,  0, 25, 52,  0, 50, 52, 55, 42,\n",
      "         0, 57, 38, 49, 48, 46, 51, 44,  0, 52, 51,  4, 57, 10,  0, 49, 42, 57,\n",
      "         0, 46, 57,  0, 39, 42,  0, 41, 52, 51, 42,  9,  0, 38, 60, 38, 62,  5,\n",
      "         0, 38, 60, 38, 62,  1,  0,  0, 30, 42, 40, 52, 51, 41,  0, 14, 46, 57,\n",
      "        46, 63, 42, 51,  9,  0, 26, 51, 42,  0, 60, 52, 55, 41,  5,  0, 44, 52,\n",
      "        52, 41,  0, 40, 46, 57, 46, 63, 42, 51, 56,  7,  0,  0, 17, 46, 55, 56,\n",
      "        57,  0, 14, 46, 57, 46, 63, 42, 51,  9,  0, 34, 42,  0, 38, 55, 42,  0,\n",
      "        38, 40, 40, 52, 58, 51, 57, 42, 41,  0, 53, 52, 52, 55,  0, 40, 46, 57,\n",
      "        46, 63, 42, 51, 56,  5,  0, 57, 45, 42,  0, 53, 38, 57, 55, 46, 40, 46,\n",
      "        38, 51, 56,  0, 44, 52, 52, 41,  7,  0, 34, 45, 38, 57,  0, 38, 58, 57,\n",
      "        45, 52, 55, 46, 57, 62,  0, 56, 58, 55, 43, 42, 46, 57, 56,  0, 52, 51,\n",
      "         0, 60, 52, 58, 49, 41,  0, 55, 42, 49, 46, 42, 59, 42,  0, 58, 56,  9,\n",
      "         0, 46, 43,  0, 57, 45, 42, 62,  0, 60, 52, 58, 49, 41,  0, 62, 46, 42,\n",
      "        49, 41,  0, 58, 56,  0, 39, 58, 57,  0, 57, 45, 42,  0, 56, 58, 53, 42,\n",
      "        55, 43, 49, 58, 46, 57, 62,  5,  0, 60, 45, 46, 49, 42,  0, 46, 57,  0,\n",
      "        60, 42, 55, 42,  0, 60, 45, 52, 49, 42, 56, 52, 50, 42,  5,  0, 60, 42,\n",
      "         0, 50, 46, 44, 45, 57,  0, 44, 58, 42, 56, 56,  0, 57, 45, 42, 62,  0,\n",
      "        55, 42, 49, 46, 42, 59, 42, 41,  0, 58, 56,  0, 45, 58, 50, 38, 51, 42,\n",
      "        49, 62, 10,  0, 39, 58, 57,  0, 57, 45, 42, 62,  0, 57, 45, 46, 51, 48,\n",
      "         0, 60, 42,  0, 38, 55, 42,  0, 57, 52, 52,  0, 41, 42, 38, 55,  9,  0,\n",
      "        57, 45, 42,  0, 49, 42, 38, 51, 51, 42, 56, 56,  0, 57, 45, 38, 57,  0,\n",
      "        38, 43, 43, 49, 46, 40, 57, 56,  0, 58, 56,  5,  0, 57, 45, 42,  0, 52,\n",
      "        39, 47, 42, 40, 57,  0, 52, 43,  0, 52, 58, 55,  0, 50, 46, 56, 42, 55,\n",
      "        62,  5,  0, 46, 56,  0, 38, 56,  0, 38, 51,  0, 46, 51, 59, 42, 51, 57,\n",
      "        52, 55, 62,  0, 57, 52,  0, 53, 38, 55, 57, 46, 40, 58, 49, 38, 55, 46,\n",
      "        56, 42,  0, 57, 45, 42, 46, 55,  0, 38, 39, 58, 51, 41, 38, 51, 40, 42,\n",
      "        10,  0, 52, 58, 55,  0, 56, 58, 43, 43, 42, 55, 38, 51, 40, 42,  0, 46,\n",
      "        56,  0, 38,  0, 44, 38, 46, 51,  0, 57, 52,  0, 57, 45, 42, 50,  0, 23,\n",
      "        42, 57,  0, 58, 56,  0, 55, 42, 59, 42, 51, 44, 42,  0, 57, 45, 46, 56,\n",
      "         0, 60, 46, 57, 45,  0, 52, 58, 55,  0, 53, 46, 48, 42, 56,  5,  0, 42,\n",
      "        55, 42,  0, 60, 42,  0, 39, 42, 40, 52, 50, 42,  0, 55, 38, 48, 42, 56,\n",
      "         9,  0, 43, 52, 55,  0, 57, 45, 42,  0, 44, 52, 41, 56,  0, 48, 51, 52,\n",
      "        60,  0, 20,  0, 56, 53, 42, 38, 48,  0, 57, 45, 46, 56,  0, 46, 51,  0,\n",
      "        45, 58, 51, 44, 42, 55,  0, 43, 52, 55,  0, 39, 55, 42, 38, 41,  5,  0,\n",
      "        51, 52, 57,  0, 46, 51,  0, 57, 45, 46, 55, 56, 57,  0, 43, 52, 55,  0,\n",
      "        55, 42, 59, 42, 51, 44, 42,  7,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(' '.join(text)), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "acdd5c4e-8f6b-41b8-9abf-dfa4cb37b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "026042ba-7e4a-4012-ba3b-5c90b04e1f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For context=tensor([17]), target=tensor(46)\n",
      "For context=tensor([17, 46]), target=tensor(55)\n",
      "For context=tensor([17, 46, 55]), target=tensor(56)\n",
      "For context=tensor([17, 46, 55, 56]), target=tensor(57)\n",
      "For context=tensor([17, 46, 55, 56, 57]), target=tensor(0)\n",
      "For context=tensor([17, 46, 55, 56, 57,  0]), target=tensor(14)\n",
      "For context=tensor([17, 46, 55, 56, 57,  0, 14]), target=tensor(46)\n",
      "For context=tensor([17, 46, 55, 56, 57,  0, 14, 46]), target=tensor(57)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size+1]\n",
    "y = train_data[1:block_size+1]\n",
    "# lets check the target for each sub sequence of characters\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"For {context=}, {target=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "99b39a51-3f4a-477a-a8df-90aa81f8066c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([4, 8]), y.shape=torch.Size([4, 8])\n",
      "For sequence=[58], target=56\n",
      "For sequence=[58, 56], target=0\n",
      "For sequence=[58, 56, 0], target=57\n",
      "For sequence=[58, 56, 0, 57], target=55\n",
      "For sequence=[58, 56, 0, 57, 55], target=38\n",
      "For sequence=[58, 56, 0, 57, 55, 38], target=46\n",
      "For sequence=[58, 56, 0, 57, 55, 38, 46], target=57\n",
      "For sequence=[58, 56, 0, 57, 55, 38, 46, 57], target=52\n",
      "batch sentence: input: us trait | output: s traito\n",
      "For sequence=[29], target=9\n",
      "For sequence=[29, 9], target=0\n",
      "For sequence=[29, 9, 0], target=14\n",
      "For sequence=[29, 9, 0, 14], target=52\n",
      "For sequence=[29, 9, 0, 14, 52], target=50\n",
      "For sequence=[29, 9, 0, 14, 52, 50], target=42\n",
      "For sequence=[29, 9, 0, 14, 52, 50, 42], target=5\n",
      "For sequence=[29, 9, 0, 14, 52, 50, 42, 5], target=0\n",
      "batch sentence: input: R: Come, | output: : Come, \n",
      "For sequence=[33], target=20\n",
      "For sequence=[33, 20], target=25\n",
      "For sequence=[33, 20, 25], target=14\n",
      "For sequence=[33, 20, 25, 14], target=16\n",
      "For sequence=[33, 20, 25, 14, 16], target=25\n",
      "For sequence=[33, 20, 25, 14, 16, 25], target=31\n",
      "For sequence=[33, 20, 25, 14, 16, 25, 31], target=20\n",
      "For sequence=[33, 20, 25, 14, 16, 25, 31, 20], target=26\n",
      "batch sentence: input: VINCENTI | output: INCENTIO\n",
      "For sequence=[26], target=9\n",
      "For sequence=[26, 9], target=0\n",
      "For sequence=[26, 9, 0], target=31\n",
      "For sequence=[26, 9, 0, 31], target=45\n",
      "For sequence=[26, 9, 0, 31, 45], target=52\n",
      "For sequence=[26, 9, 0, 31, 45, 52], target=58\n",
      "For sequence=[26, 9, 0, 31, 45, 52, 58], target=0\n",
      "For sequence=[26, 9, 0, 31, 45, 52, 58, 0], target=41\n",
      "batch sentence: input: O: Thou  | output: : Thou d\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print(f'{x.shape=}, {y.shape=}')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for bl in range(block_size):\n",
    "        print(f\"For sequence={x[b,:bl+1].tolist()}, target={y[b,bl]}\")\n",
    "    print(f\"batch sentence: input: {decode(x[b, :].tolist())} | output: {decode(y[b, :].tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "00f96450-0c34-4ab7-ba46-f44fd10bd5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "loss=tensor(4.4599, grad_fn=<NllLossBackward0>) - Expected Loss = 4.174387269895637\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C) stands for batch x time x vocab_size\n",
    "        B,T,C = logits.shape\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # stretching logits and targets tensors\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T) # equivalent to targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits,_ = self(idx) # B,T,C\n",
    "            logits = logits[:, -1, :] # B,C\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(x, y)\n",
    "print(logits.shape)\n",
    "print(f'{loss=} - Expected Loss = {-math.log(1/65)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a31c1363-abec-4ee3-8668-ca4a261a8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" TCZ3EVgkqYUlLOy$WfZsbmH'WViL-N-sy S&Z:cLAlO;NZpEy!rEOt3:S$oNGfGt;NgNIjyPlc!QUDEYar&all.YcW&tb3!EY q'\""
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial index\n",
    "idx = torch.zeros((1,1), dtype=torch.long) # B,T\n",
    "decode(m.generate(idx, max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bdbd0d6b-9a87-48e4-8dac-1d1578bde45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.453453779220581\n"
     ]
    }
   ],
   "source": [
    "# Training Bigram Model\n",
    "\n",
    "# Defining optimizer \n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size=32\n",
    "\n",
    "# Training loop\n",
    "for i in range(1000):\n",
    "    x_batch, y_batch = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(x_batch, y_batch)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "eca230ac-4cc2-458b-8e8c-38ca66c6a014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thanendegersourave Yort cr I, tryor t, wisthore ld feephane  ple GLORENGoverspltout:cord dandwh Oxe te: gheduglll se, f hethamyo he ro ELOurad porrs p ape he weverin: omy he, at, swobyowhano UJHATOLIs I soriacowarest asewe TISoushidol d, oper ls oou freact fltit m CET: twatoo Bosend Shathyo hu k? Ri'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial index\n",
    "idx = torch.zeros((1,1), dtype=torch.long) # B,T\n",
    "decode(m.generate(idx, max_new_tokens=300)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d230c80e-7347-486a-8e3d-51c50e0c7bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "da8552c2-d70f-4ecd-af33-98c27a07288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_token.shape=torch.Size([1, 1, 16])\n",
      "x_pos.shape=torch.Size([8, 16])\n",
      "torch.Size([1, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "logits,_ = m(idx) # B,T, vocab_size\n",
    "logits = logits[:, -1, :] # B, vocab_size\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "idx = torch.cat((idx, idx_next), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "87c18ebb-88f2-41f6-82d3-aae6e22f6e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[342], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[1;32m     55\u001b[0m m \u001b[38;5;241m=\u001b[39m BigramLanguageModel_v2(vocab_size)\n\u001b[0;32m---> 56\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m - Expected Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m65\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[342], line 19\u001b[0m, in \u001b[0;36mBigramLanguageModel_v2.forward\u001b[0;34m(self, x, targets)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     x_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T, n_embd) stands for batch x time x n_embd\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     x_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(block_size)) \u001b[38;5;66;03m# (T, n_embd) stands for batch x time x n_embd\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x_token \u001b[38;5;241m+\u001b[39m x_pos \u001b[38;5;66;03m# (B, T, n_embd) + (T, n_embd) \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.10/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "# Adding positional embedding and linear layer to model\n",
    "n_embd = 32\n",
    "head_size = 16\n",
    "\n",
    "class BigramLanguageModel_v2(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # (C, N)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embd) # (B, N)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        \n",
    "        self.lm_head = nn.Linear(head_size, vocab_size) # (N, C)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T,T)))\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x_token = self.token_embedding_table(x) # (B,T, n_embd) stands for batch x time x n_embd\n",
    "        x_pos = self.positional_embedding_table(torch.arange(block_size)) # (T, n_embd) stands for batch x time x n_embd\n",
    "        x = x_token + x_pos # (B, T, n_embd) + (T, n_embd) \n",
    "        \n",
    "        k = key(x) # (B, T, head_size)\n",
    "        q = query(x) # (B, T, head_size)\n",
    "        \n",
    "        tril = torch.tril(torch.ones(T,T))\n",
    "        weights = q @ k.transpose(-2, -1) * head_size ** -0.5 # (B, T, T)\n",
    "        weights = weights.masked_fill(tril == 0, float('-inf')) # This is the form of guaranteeing future time tokens do not communicate with former tokens.\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        v = value(x)\n",
    "        x = weights @ v # (B,T,T) @ (B,T,head_size) = (B, T, head_size)\n",
    "        \n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)    \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # stretching logits and targets tensors\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T) # equivalent to targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits,_ = self(idx[:, -block_size:]) # always analysing only previous character\n",
    "            logits = logits[:, -1, :] # B, vocab_size\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel_v2(vocab_size)\n",
    "logits, loss = m(x, y)\n",
    "print(f'{loss=} - Expected Loss = {-math.log(1/65)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "39970631-49d6-4122-a6a9-04e0aac5bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.350381851196289\n"
     ]
    }
   ],
   "source": [
    "# Training Bigram Model\n",
    "\n",
    "# Defining optimizer \n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size=32\n",
    "\n",
    "# Training loop\n",
    "for i in range(1000):\n",
    "    x_batch, y_batch = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(x_batch, y_batch)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "62dfa0c6-0ac1-4a46-a8c9-cce5737d8c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" bllillumaug s OMPKE: flle AROLEZApr? Samo angrutave e t Hasif l s,-tro, hetr is the'ttouto wicketad qus lave is Moou than urotoulcis LOR: NI' s'lothonereente. Thake the'l ' bigre ch'l bels aghitur mor-n:  ': amsordece  frete t Whalld  IOMy wee bor  loo myout. ms t m trand at tw harspe nd thenoulwiar\""
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial index\n",
    "idx = torch.zeros((1,1), dtype=torch.long) # B,T\n",
    "decode(m.generate(idx, max_new_tokens=300)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392be4b-845e-4e26-a8fb-aad8b4b0b934",
   "metadata": {},
   "source": [
    "## Mathematical Trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d567b55f-be41-4cbf-8848-a6c206e1f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # Batch x Time x Channel\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "06d5fb9c-a661-4c3a-9f04-682c69c4283d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 ms, sys: 244 µs, total: 2.44 ms\n",
      "Wall time: 2.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2573, -1.0673],\n",
       "         [ 0.2890, -1.5117],\n",
       "         [-0.0741, -1.1759],\n",
       "         [-0.0733, -1.0102],\n",
       "         [-0.0298, -0.7626],\n",
       "         [-0.0628, -0.7502],\n",
       "         [-0.0277, -0.5573],\n",
       "         [-0.2171, -0.5309]],\n",
       "\n",
       "        [[ 0.6903, -0.1961],\n",
       "         [ 0.3482, -0.5813],\n",
       "         [ 0.3516, -0.3518],\n",
       "         [ 0.5753,  0.0477],\n",
       "         [ 0.2600, -0.0438],\n",
       "         [ 0.1816, -0.1691],\n",
       "         [ 0.1742, -0.4228],\n",
       "         [ 0.1600, -0.3997]],\n",
       "\n",
       "        [[-0.2978,  0.0172],\n",
       "         [ 0.0213,  0.5928],\n",
       "         [-0.2033,  0.5208],\n",
       "         [-0.1053,  0.5195],\n",
       "         [-0.2123,  0.0208],\n",
       "         [-0.3698,  0.0656],\n",
       "         [-0.2289, -0.0062],\n",
       "         [-0.1179,  0.0769]],\n",
       "\n",
       "        [[-1.7662,  0.5860],\n",
       "         [-0.5895,  0.4360],\n",
       "         [-0.3902,  0.2066],\n",
       "         [-0.6238,  0.2022],\n",
       "         [-0.6090, -0.1312],\n",
       "         [-0.6004, -0.2250],\n",
       "         [-0.5611, -0.0151],\n",
       "         [-0.6369, -0.0644]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.manual_seed(1338)\n",
    "\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (T,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "\n",
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4c896ba3-7b96-4711-8ffd-5304ff543a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 ms, sys: 1.17 ms, total: 12.5 ms\n",
      "Wall time: 2.63 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2573, -1.0673],\n",
       "         [ 0.2890, -1.5117],\n",
       "         [-0.0741, -1.1759],\n",
       "         [-0.0733, -1.0102],\n",
       "         [-0.0298, -0.7626],\n",
       "         [-0.0628, -0.7502],\n",
       "         [-0.0277, -0.5573],\n",
       "         [-0.2171, -0.5309]],\n",
       "\n",
       "        [[ 0.6903, -0.1961],\n",
       "         [ 0.3482, -0.5813],\n",
       "         [ 0.3516, -0.3518],\n",
       "         [ 0.5753,  0.0477],\n",
       "         [ 0.2600, -0.0438],\n",
       "         [ 0.1816, -0.1691],\n",
       "         [ 0.1742, -0.4228],\n",
       "         [ 0.1600, -0.3997]],\n",
       "\n",
       "        [[-0.2978,  0.0172],\n",
       "         [ 0.0213,  0.5928],\n",
       "         [-0.2033,  0.5208],\n",
       "         [-0.1053,  0.5195],\n",
       "         [-0.2123,  0.0208],\n",
       "         [-0.3698,  0.0656],\n",
       "         [-0.2289, -0.0062],\n",
       "         [-0.1179,  0.0769]],\n",
       "\n",
       "        [[-1.7662,  0.5860],\n",
       "         [-0.5895,  0.4360],\n",
       "         [-0.3902,  0.2066],\n",
       "         [-0.6238,  0.2022],\n",
       "         [-0.6090, -0.1312],\n",
       "         [-0.6004, -0.2250],\n",
       "         [-0.5611, -0.0151],\n",
       "         [-0.6369, -0.0644]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# We could use these matrix multiplication tricks to make the attention heads consider only past rows in their calculations\n",
    "weight = torch.tril(torch.ones(T,T))\n",
    "weight /= weight.sum(1, keepdims=True)\n",
    "\n",
    "xbow2 = weight @ x # (B, T, T) @ (B, T, C)\n",
    "xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5ffc8e52-f081-45eb-bd00-cb32cf763e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b3549c1e-3473-461d-81e2-54673811828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # This is the form of guaranteeing future time tokens do not communicate with former tokens.\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b9c2d91d-c090-4b00-a8d9-bcb159842eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc692c4-6f9f-4e98-a539-e4c783854f34",
   "metadata": {},
   "source": [
    "### Self Attention Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9e1a9ca8-c0f0-44be-8c40-6dfa2e7f23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing self-attention head\n",
    "n_embd    = 32\n",
    "head_size = 16\n",
    "\n",
    "x = torch.randint(high=vocab_size, size=(B,T))\n",
    "\n",
    "# Self attention solves the problem of gathering information from the past to the current token in a data dependent way\n",
    "token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "\n",
    "key   = nn.Linear(n_embd, head_size, bias=False)\n",
    "query = nn.Linear(n_embd, head_size, bias=False)\n",
    "value = nn.Linear(n_embd, head_size, bias=False)\n",
    "\n",
    "x = token_embedding(x)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "v = value(x)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "weights = q @ k.transpose(-2, -1) # (B, T, T)\n",
    "weights = weights.masked_fill(tril == 0, float('-inf')) # This is the form of guaranteeing future time tokens do not communicate with former tokens.\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "x = weights @ v * head_size ** -0.5 # (B,T,T) @ (B,T,head_size) = (B, T, head_size)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "10656f4e-41d5-4f83-af04-2270207bc4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8646, 0.1354, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4214, 0.0770, 0.5016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3769, 0.2137, 0.1746, 0.2347, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3459, 0.2613, 0.1767, 0.1144, 0.1016, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2567, 0.1610, 0.0721, 0.2641, 0.0545, 0.1916, 0.0000, 0.0000],\n",
       "         [0.0457, 0.4722, 0.0211, 0.0212, 0.2727, 0.0902, 0.0769, 0.0000],\n",
       "         [0.0264, 0.0572, 0.0157, 0.0676, 0.0944, 0.0211, 0.0492, 0.6684]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8535, 0.1465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1058, 0.5093, 0.3849, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8217, 0.1011, 0.0442, 0.0330, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1501, 0.2350, 0.3374, 0.1273, 0.1501, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0550, 0.0991, 0.0413, 0.7332, 0.0550, 0.0165, 0.0000, 0.0000],\n",
       "         [0.0219, 0.0314, 0.0294, 0.5737, 0.0219, 0.1168, 0.2047, 0.0000],\n",
       "         [0.0580, 0.1588, 0.0957, 0.1656, 0.0580, 0.0490, 0.1808, 0.2341]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0732, 0.9268, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1684, 0.3117, 0.5199, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0178, 0.8256, 0.0624, 0.0942, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6246, 0.1123, 0.0672, 0.0665, 0.1294, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3259, 0.0656, 0.1689, 0.0562, 0.2529, 0.1305, 0.0000, 0.0000],\n",
       "         [0.0440, 0.0302, 0.1592, 0.0510, 0.2683, 0.2296, 0.2177, 0.0000],\n",
       "         [0.0131, 0.6091, 0.0461, 0.0695, 0.1210, 0.0454, 0.0263, 0.0695]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1456, 0.8544, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0338, 0.4104, 0.5558, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0937, 0.6700, 0.0541, 0.1823, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5302, 0.0899, 0.1035, 0.1116, 0.1648, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0692, 0.4949, 0.0399, 0.1347, 0.1267, 0.1347, 0.0000, 0.0000],\n",
       "         [0.1957, 0.1601, 0.0278, 0.1516, 0.0403, 0.1516, 0.2729, 0.0000],\n",
       "         [0.0509, 0.1630, 0.0060, 0.0933, 0.0551, 0.0933, 0.3653, 0.1732]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights become data dependent according to each input from the batch...\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "938756e5-80dd-4855-8b58-cff74cae045a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2811, grad_fn=<VarBackward0>),\n",
       " tensor(0.3214, grad_fn=<VarBackward0>),\n",
       " tensor(0.0465, grad_fn=<VarBackward0>))"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var(), q.var(), weights.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4c9b6aab-c63d-4663-af9b-dee24ad3a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(B,T,head_size)\n",
    "b = torch.randn(B,T,head_size)\n",
    "\n",
    "w = a @ b.transpose(-2,-1) * head_size ** -0.5 # scaling w values to variance close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "13072239-0fae-481e-8966-91d9a3527476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0302), tensor(0.9864), tensor(1.0720))"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.var(), b.var(), w.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12d123-e356-40cf-bcc7-31ef9f4cb025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
